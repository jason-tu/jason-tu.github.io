<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Singularity|artificialIntelligence</title>
    <link href=
    'https://netdna.bootstrapcdn.com/bootstrap/3.1.0/css/bootstrap.css' rel=
    'stylesheet prefetch'>
    <link href="./style.css" rel="stylesheet">
    <title></title>
</head>
<style type "text/css">
<!--
/* @group Blink */
.blink {
	-webkit-animation: blink .75s linear infinite;
	-moz-animation: blink .75s linear infinite;
	-ms-animation: blink .75s linear infinite;
	-o-animation: blink .75s linear infinite;
	 animation: blink .75s linear infinite;
}
@-webkit-keyframes blink {
	0% { opacity: 1; }
	50% { opacity: 1; }
	50.01% { opacity: 0; }
	100% { opacity: 0; }
}
@-moz-keyframes blink {
	0% { opacity: 1; }
	50% { opacity: 1; }
	50.01% { opacity: 0; }
	100% { opacity: 0; }
}
@-o-keyframes blink {
	0% { opacity: 1; }
	50% { opacity: 1; }
	50.01% { opacity: 0; }
	100% { opacity: 0; }
}
@keyframes blink {
	0% { opacity: 1; }
	50% { opacity: 1; }
	50.01% { opacity: 0; }
	100% { opacity: 0; }
}
/* @end */
-->
</style>
<body>
    <div id="container-fluid">
        <div class="row come-in">
            <h1 class="text-center"><font color="white" size="30">Singularity<strong class="tab blink">|</strong></font><font color="blue" face="consolas" size="5">artificialIntelligence</font></h1>
            
			
            <div class="col-lg-6 col-md-6 col-sm-12 col-xs-12" id="divTheSingularityIsntNear">
                <div class="panel panel-default">
                    <div class="panel-heading" style="background: #add8e6">
                        <a href=
                        "https://www.technologyreview.com/s/425733/paul-allen-the-singularity-isnt-near/"
                        style="color: #000000">The Singularity Isn't Near</a>
                        - Paul Allen
                    </div>
                    <div class="panel-body">
                        <p>Since the entire world concerning singularity seems to be against Ray Kurzweil, Paul Allen dutifully starts off bashing Kurzweil’s predictions. Discrediting Kurzweil’s usage of the Law of Accelerating Returns, due to lack of being physical laws, Allen continues on to develop his own points after spending half the article attempting to discredit Kurzweil’s prediction of 2045 being the date for singularity.<br><br>
The secondary point rests upon the complexity of the human brain. Many scientific estimates about the date of singularity rests upon finding how the human brain works. Allen brings up a point about a bird's flight, stating that we: “also need to know how everything functions together.” His multi-faceted approach towards stating that it is quite hard to realize and understand how the brain works goes to push back Kurzweil’s predictions.<br><br>
The final point consists of using current day examples, such as IBM’s Watson. Although Watson is a form of AI, it is a primitive form of AI. It has not done much towards society, and has no meaningful everyday applications, nor any applications overall.<br><br> 
Allen definitely targets this essay towards Kurzweil, especially concerning the predicted date of achieving singularity. Allen’s main focal points rest on the complexity brake, a theory that artificial intelligence will be unable to achieve singularity due to the complexity of the human brain, and the lack of current AI technology.<br><br>
</p>
                    </div>
                </div>
                <div class="panel panel-default fadeInDown">
                    <div class="panel-body">
                        <div id="theSingularityIsntNear">
                            <button class="btn btn-primary" onclick=
                            "showTheSingularityIsntNear()">Show Source</button>
                        </div>
                    </div>
                </div>
                <div class="panel panel-default fadeInDown">
                    <div class="panel-body">
                        <p>As the co-founder of Microsoft, Paul G. Allen's
                        philanthropic contributions have exceeded $2 billion.
                        He has founded the Allen Institute for Brain Science,
                        Institute for Artificial Intelligence, Institute for
                        Cell Science, and Vulcan Aerospace. In adittion, he
                        owns the Seattle Seahawks and Portland Trail Blazers.
                        Paul G. Allen is invested in the arts as a collector,
                        guitarist, and filmmaker. His personal website may be
                        found <a href="http://www.paulallen.com/">here</a>.</p>
                    </div>
                </div>
                <div class="panel panel-default fadeInDown">
                    <div class="panel-body">
                        <p>Allen, Paul G. "The Singularity Isn't Near." MIT
                        Technology Review. MIT Technology Review, 12 Oct. 2011.
                        Web. 29 Mar. 2016.</p>
                    </div>
                </div>
            </div>
			
            
            <div class="col-lg-6 col-md-6 col-sm-12 col-xs-12" id=
            "divDontUnderestimateTheSingularity">
                <div class="panel panel-default">
                    <div class="panel-heading" style="background: #add8e6">
                        <a href=
                        "https://www.technologyreview.com/s/425818/kurzweil-responds-dont-underestimate-the-singularity/"
                        style="color: #000000">Don't Underestimate the
                        Singularity</a> - Ray Kurzweil
                    </div>
                    <div class="panel-body">
                        <p>Interestingly enough, Kurzweil responds to Paul Allen’s biting essay. Kurzweil starts off chiding Allen, stating that the book Allen discredits was “co-written with [Allen’s] colleague.” Kurzweil then proceeds to destroy Allen, offering commentaries such as: “it appears that he has not actually read the book” and “at least he could have responded to what I actually wrote.”<br><br>
Addressing Allen’s complaint about the current state of AI, Kurzweil cites Intel, arguably the most prominent manufacturer in CPU technology, and their work in breaking the sixth paradigm, which would allow for computing in three dimensions rather than the current two dimensions. Kurzweil moves on to defend IBM’s Watson, which Allen degrades as making judgment solely based off of statistical information rather than true knowledge. Kurzweil offers the opinion that humans use the same statistical knowledge process that Watson uses to claim true knowledge. <br><br>
The complexity brake is not an issue for Kurzweil. He acknowledges Allen’s opinion about the complexity of the brain, yet Kurzweil goes on to discredit it by removal of the brain’s redundant connections. The massive repetition of processes within the brain allow Kurzweil to discredit Allen’s argument concerning this topic.<br><br>
The concluding remark made is worth quoting: “we build these tools to extend our own reach.”<br><br>
</p>
                    </div>
                </div>
                <div class="panel panel-default fadeInDown">
                    <div class="panel-body">
                        <div id="dontUnderestimateTheSingularity">
                            <button class="btn btn-primary" onclick=
                            "showDontUnderestimateTheSingularity()">Show
                            Source</button>
                        </div>
                    </div>
                </div>
                <div class="panel panel-default fadeInDown">
                    <div class="panel-body">
                        <p>As one of the pioneers of futurology, Kurzweil has
                        been involved in projects concerning text recongnition.
                        Having received the National Medal of Technology and
                        Innovation in 1999, the United States' highest honor
                        in technology, Kurzweil has also authored seven books.
                        Currently employed by Google Inc., he is a graduate of
                        the Massachusetts Institute of Technology. More
                        information may be found on Kurzweil's website located
                        <a href="http://www.kurzweilai.net/">here</a>.</p>
                    </div>
                </div>
                <div class="panel panel-default fadeInDown">
                    <div class="panel-body">
                        <p>Kurzweil, Ray. "Don't Underestimate the
                        Singularity." MIT Technology Review. MIT Technology
                        Review, 20 Oct. 2011. Web. 29 Mar. 2016.</p>
                    </div>
                </div>
            </div>
			

            <div class="panel-body" align="middle">
                <img src="comic1.jpg" align="middle"></img>
					<p>Campbell, John. "Pictures for Sad Children." N.p., n.d. Web. 10 Apr. 2016. &lt;http://i.imgur.com/1WrKzbD.jpg&gt;. </p>
            </div>
			
			
            <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12" id="divShouldWeFearVideo">
                <div class="panel panel-default">
                    <div class="panel-heading" style="background: #85B0E6">
                        <a href=
                        "https://www.youtube.com/watch?v=TcX_7SVI_hA"
                        style="color: #000000">Should We Fear Or Welcome The Singularity?</a> - Noble Week Dialogue 2015
                    </div>
                    <div class="panel-body">
                        <p>	Stuart Russell starts the controversial opinion of this talk by confronting Ray Kurzweil’s optimistic points about singularity. Russell brings up the story of King Midas, stating that once we “put a purpose into a machine… be sure the purpose is exactly the purpose you desire.” Max Tegmark develops both points further, discussing how we should both fear it, and develop it. Although it’s a wonderful piece of technology, said technology is a double-edged sword. He brings up multiple points about how we as humans learn from mistakes, yet we cannot apply this same mindset to AI. The potential that AI brings for making a mistake once we integrate it into our daily lives is just too much to bear. Harry Shum then leads the conversation into the topic of building AI before we can determine ethical standards and impacts for AI.
	<br><br>Overall, interpretations of AI when it reaches singularity was the main topic of this discussion. If an AI makes a mistake, the rest of the AI industry will be condemned. Society as a whole will have trouble recovering, even if it means something menial such as locking an owner out of their house by accident. Russell’s example included given a command to a household AI to cook a meal. Said AI will then grab the nearest edible food, and start cooking it. The nearest edible food could be a household cat. The dangers that AI accumulates are not dangers towards human society, so much as dangers to itself. AI will definitely start small, committing mistakes on a menial level. If it creates one mistake, it no longer will be trustworthy, and hence will not be delegated responsibility to create mistakes at a higher level (where human life may be at stake). <br><br>As a whole, the talk represented not only the upcoming apex of singularity, but rather the potential and pathways AI has to take to fully integrate itself into our human lives. The dangers of such integration are avoided by affirmation of opinion that AI will start small (mistakes committed early will doom AI, hence major mistakes will be unable to happen). As a secondary topic, this discussion did talk about the development of AI as a being with emotional interpretations able to fully understand what a human means, not what a human says.

</p>
                    </div>
                </div>
                <div class="panel panel-default fadeInDown">
                    <div class="panel-body">
                        <div id="shouldWeFearVideo">
                            <button class="btn btn-primary" onclick=
                            "showShouldWeFearVideo()">Show
                            Source</button>
                        </div>
                    </div>
                </div>
                <div class="panel panel-default fadeInDown">
                    <div class="panel-body">
                        <p>Harry Shum - Microsoft Research EVP of Tech. Shum is the Corporate Vice President of Bing Product Development and is Microsoft's Executive Vice Presidnet, Technology & Research.</p>
                        <p>Max Tegmark - Cosmologist, MIT. Funded by Elon Musk, he investigates the risk artificial intelligence could bring.</p>
                        <p>Stuart Russell - Professor of Computer Science, UC Berkeley. As a graduate from Oxford and Stanford, Russell is appointed as the Blaise Pascal Chair, and has received the IJCAI Comptuers and Thought Award in 1995.</p>
                        <p>Ray Kurzweil - Futurist, Google Director of Engineering. See above sources for summary.</p>
                        <p>Moderator: Margaret Boden - Professor of Cognitive Science, University of Sussex. As a graduate from Harvard and Cambridge, Boden is known for her work in AI, cognitive and computer science, psychology, and philosophy.</p>
                    </div>
                </div>
                <div class="panel panel-default fadeInDown">
                    <div class="panel-body">
                        <p>The Nobel Prize. "Should We Fear or Welcome the Singularity?" YouTube. YouTube, 20 Jan. 2016. Web. 30 Mar. 2016.</p>
                    </div>
                </div>
            </div>
			
			
			<div class="panel-body" align="middle">
                <img src="comic2.gif" align="middle"></img>
					<p>Adams, Scott. Dilbert. N.p., n.d. Web. 10 Apr. 2016. &lt;http://dilbert.com/strip/2013-07-04&gt;. </p>
            </div>
			
            
            <div class="col-lg-6 col-md-6 col-sm-12 col-xs-12" id=
            "divComingSingularity">
                <div class="panel panel-default">
                    <div class="panel-heading" style="background: #647EBE">
                        <a href=
                        "https://docs.google.com/file/d/0B-5-JeCa2Z7hN1RfRDlqcXpVYzA/edit"
                        style="color: #000000">The Coming Technological Singularity: How to Survive in the Post-Human Era</a> - Vernor Vinge
                    </div>
                    <div class="panel-body">
                        <p>Singularity is redefined as the instantaneous moment when AI becomes as smart as human. Vernor Vinge hones in on the exact moment, predicting that scientists will know very little about the exact moment AI achieves singularity. Once AI does achieve singularity, it’ll explode faster than we could possibly imagine. Some scientist could make a minor change (changing a module, a line of code, etc.) that sparks the explosion of singularity. People won’t even know that AI achieved singularity before it hits them.<br><br>
Vinge’s main point lies on what happens after Singularity. Since we as humans cannot think on a level higher than our own, what happens when singularity is reached will be far beyond our control. What happens will be on a thought processing level that we as humans may be unable to even imagine of today. <br><br>
After deliberating on the consequences and impulse that singularity will bring, Vinge quickly addresses the possibility of singularity. He states that “we cannot prevent the Singularity, that its coming is an inevitable consequence of the humans’ natural competitiveness and the possibilities inherent in technology.” <br><br>
Vinge and Kurzweil seems to have similar ideals within the realm of intelligence amplification. Intelligence amplification is the integration of artificial intelligence into humans. Essentially like The Matrix, humans will be able to “download” data to store into expanded minds. A list of seven possible ideals is presented, ranging from art production to our current usage of the internet within our daily lives.<br><br>
The most important ideals that Vinge brings up rest within his last few paragraphs. The presentation of immortality as a product of singularity are brought up. Not only could ideas of any common person be immortalized, but humans could begin to develop thought consciousness beyond our current limiting methods of speech and text. Since rapid rates of communication will be easily feasible, different forms of thoughts will be developed. Due to these new methodologies of communication and possibilities of things we as humans only imagined were possible within fragments of dreams, what could happen in the future is impossible to think of now.<br><br>
</p>
                    </div>
                </div>
                <div class="panel panel-default fadeInDown">
                    <div class="panel-body">
                        <div id="comingSingularity">
                            <button class="btn btn-primary" onclick=
                            "showComingSingularity()">Show
                            Source</button>
                        </div>
                    </div>
                </div>
                <div class="panel panel-default fadeInDown">
                    <div class="panel-body">
                        <p>Vernor Vinge, a former Professor of Mathematics at San Diego State University, has written five Hugo Award-winning novels and novellas. After retiring from San Diego State University in 2000, Vinge dedicated his life to writing. Primarily a science fiction author, he focuses on writing about artificial intelligence and singularity. He was also the Writer Guest of Honor at the 60th World Science Fiction Convention in 2002. His work can also be found in Nature magazine, as well as the Institute of Electrical and Electronics Engineers’ magazine.</a></p>
                    </div>
                </div>
                <div class="panel panel-default fadeInDown">
                    <div class="panel-body">
                        <p>Vinge, Vernor. "The Coming Technological Singularity: How to Survive in the Post-human Era." Diss. San Diego State U, 1993. Abstract. In NASA. Lewis Research Center, Vision 21: Interdisciplinary Science and Engineering in the Era of Cyberspace P 11-22 (SEE N94-27358 07-12) (n.d.): 11-22. Print.</p>
                    </div>
                </div>
            </div>
			
			
			<div class="col-lg-6 col-md-6 col-sm-12 col-xs-12" id=
            "divSingularityMayNever">
                <div class="panel panel-default">
                    <div class="panel-heading" style="background: #647EBE">
                        <a href=
                        "http://arxiv.org/pdf/1602.06462v1.pdf"
                        style="color: #000000">The Singularity May Never Be Near</a> - Toby Walsh
                    </div>
                    <div class="panel-body">
                        <p>Toby Walsh’s paper definitely raises interesting implications. Although Walsh believe the singularity will happen, Walsh does not believe in a singularity explosion, citing multiple sources and theories to back his statement up. <br><br> The “Fast Thinking Dog” argument states that although silicon is faster than our brains, intelligence is consistent of more than just raw processing power. The analogy of a dog comes from the statement that a faster dog will still be unable to play chess. <br><br> The “Anthropcentric” argument questions the intelligence of the human race. If we do have the capability to build something that is somewhat intelligent, sure, it’ll explode. But that all assumes we have the capacity to build something intelligent. As humans, we are the only intelligent species on earth, and this must be for some reason, as there has been billions of years of evolution. Even if an AI was created, the true intelligence of that AI could be brought into question. Statistical interpretation may be different from true intelligence. <br><br> The “Meta-Intelligence” argument develops a theory that AI will struggle to develop more intelligent methods of machine learning, despite having loads of processing power available to it. Likening humans to AI, Walsh’s argument is that any of the current innovations in AI are hard won, making AI innovating AI potentially harder since it relies on an exponential curve. <br><br> The “Diminishing returns” argument allows for the spiraling of data complexity to be matched with the advancement of AI. With AI development, data structures will become harder to analyze, data sets will grow larger. Hence, AI will need to rewrite itself to keep up with the influx of data constantly presented. There will exist a time when AI falls behind the data available, leading to the argument of diminishing returns. <br><br> The “Limits of intelligence” argument develops the (essentially) physical boundaries presented to us by the core concept of intelligence. This argument relies on the existence of a boundary, similar to how there is a boundary for the speed of light. Once that boundary is reached by AI, the argument for the law of diminishing returns comes into play, and hardware (which does have its limits) will become the power player. <br><br> The “Computational complexity” argument relies on the basic foundation of unsolvable problems (such as the meaning of life). Computational complexity states that although AI may grow omniscient, it will still be unable to solve problems that are rhetorical in nature. <br><br> Taking these six arguments into mind, it is undoubted that AI will have a significant impact on our future, it is just a matter of how big of an impact AI can have despite these theoretical arguments. </p>
                    </div>
                </div>
                <div class="panel panel-default fadeInDown">
                    <div class="panel-body">
                        <div id="singularityMayNever">
                            <button class="btn btn-primary" onclick=
                            "showSingularityMayNever()">Show
                            Source</button>
                        </div>
                    </div>
                </div>
                <div class="panel panel-default fadeInDown">
                    <div class="panel-body">
                        <p>Toby Walsh is currently working at the University of New South Wales as a professor in artificial intelligence. Having won the <a href="https://en.wikipedia.org/wiki/Humboldt_Prize">Humboldt Prize</a> in 2014, he is also an elected Fellow of the Association for the Advancement of Artificial Intelligence as well as the European Coordinating Committee for Artificial Intelligence.</p>
                    </div>
                </div>
                <div class="panel panel-default fadeInDown">
                    <div class="panel-body">
                        <p>Walsh, Toby. "The Singularity May Never Be Near." The Singularity May Never Be Near (2016): n. pag. Cornell University Library, 2016. Web. 10 Apr. 2016. &lt;http://arxiv.org/pdf/1602.06462v1.pdf>.<p>
                    </div>
                </div>
            </div>
			
			
			<div class="panel-body" align="middle">
                <img src="comic4.jpg" align="middle"></img>
					<p>Ansari, Aziz, and Alan Young. <i>Master of None Episode 4</i>. N.d. Television.</p>
            </div>
						
			
			<div class="col-lg-6 col-md-6 col-sm-12 col-xs-12" id=
            "divManImmortal">
                <div class="panel panel-default">
                    <div class="panel-heading" style="background: #528B8B">
                        <a href=
                        "http://content.time.com/time/magazine/article/0,9171,2048299,00.html"
                        style="color: #000000">2045: The Year Man Becomes Immortal</a> - Lev Grossman
                    </div>
                    <div class="panel-body">
                        <p>This TIME entry succinctly summarizes Ray Kurzweil’s main points, especially in regard to the singularity. Kurzweil’s main focus within the scope of this article seems to be on life extension. Kurzweil mainly wants to use AI to benefit humans in a more direct way, think integrated chips.<br><br> Grossman’s foundational point lies upon the ethical and philosophical practices of the implications of singularity. He asks questions such as: “If I can scan my consciousness into a computer, am I still me?”, “What are the geopolitics and the socioeconomics of the Singularity?”, “Who decides who gets to be immortal?”, Who draws the line between sentient and nonsentient?”, “And as we approach immortality, omniscience and omnipotence, will our lives still have meaning?”, and “By beating death, will we have lost our essential humanity?”. <br><br> Such questions are answered within Kurzweil’s university, the Singularity University. But by banning such technologies from occurring, Grossman says we would need a system too comprehensive to fully take out all mentions of singularity and any danger associated with it. <br><br> Grossman concludes the article by expanding upon the future implications of singularity once again. The potential for immortality, or even swapping physical manifestations for temporary durations. The plausibility of such ideals is only enforced by the presence of an exponential curve in the rise of technology. Just a few decades prior, there were no computing devices as powerful as the phones we have in our pockets almost ubiquitously in this century.</p>
                    </div>
                </div>
                <div class="panel panel-default fadeInDown">
                    <div class="panel-body">
                        <div id="manImmortal">
                            <button class="btn btn-primary" onclick=
                            "showManImmortal()">Show
                            Source</button>
                        </div>
                    </div>
                </div>
                <div class="panel panel-default fadeInDown">
                    <div class="panel-body">
                        <p>As a graduate of both Harvard and Yale, Lev Grossman currently is a senior writer and book critic for TIME magazine, Grossman has gone on to write multiple novels. Such novels include <i>Warp</i>, <i>The Magicians</i>, <i>Codex</i>, <i>The Magician's Land</i>, and <i>The Magician King</i>. Grossman has also written for <i>The New York Times</i>, <i>Wired</i>, <i>Entertainment Weekly</i>, and <i>The Wall Street Journal</i>.</p>
                    </div>
                </div>
                <div class="panel panel-default fadeInDown">
                    <div class="panel-body">
                        <p>Grossman, Lev. "2045: The Year Man Becomes Immortal." Time. Time Inc., 10 Feb. 2011. Web. 10 Apr. 2016.</p>
                    </div>
                </div>
            </div>			
			
			
			<div class="col-lg-6 col-md-6 col-sm-12 col-xs-12" id=
            "divDebunkingAI">
                <div class="panel panel-default">
                    <div class="panel-heading" style="background: #528B8B">
                        <a href=
                        "http://arstechnica.com/information-technology/2015/12/demystifying-artificial-intelligence-no-the-singularity-is-not-just-around-the-corner/"
                        style="color: #000000">Debunking the biggest myths about artificial intelligence</a> - Rupert Goodwins
                    </div>
                    <div class="panel-body">
                        <p>Rupert Goodwins addresses many issues and myths that uneducated civilians usually procure while listening about singularity. <br><br> AI isn’t about making machines think, since having such power requires mimicking the human brain, which has over 100 billion neurons and 1,000 trillion synaptic interconnections. This biological connections requires duplication at the utmost important level. Not only that, philosophers and psychologists have yet to determine what “thought” actually is. Is it a figment of imagination? Is it consciousness? Or is it simply using statistical facts to create a sound judgment? <br><br> AI will be bound by human ethical standards. This is since AI is learning from humans. What it learns it will eventually adopt as truth. So long as it learns human ideals and ethics, it may be incorrect in terms of an overall truth, but it will be in line with societal standards of ethical means. Harmful behavior will never be intentional, unless we tell the AI that harm is good. <br><br> One of the biggest fears that AI revolutionaries such as Elon Musk have would be the usage of AI for evil means. AI development is for the most part, under open-source licensing, allowing anybody to look and review the code that is being used to develop the next human. Frankly, even if AI did manage to become evil, it will still be under control. It may be able to spread itself through means in which we find impossible, but signs will be shown way before that time that the AI being developed should be destroyed. The overall structure of the AI may be to improve exponentially and hit an intelligence explosion, but the standard that is brought to it by the human ethical boundaries will stop AI from exploding too fast, too soon. <br><br> Goodwin concludes by stating the current and hardware limitations of AI (which was recently offset by Nvidia’s new line of GPUs dedicated towards Deep Learning). The recognition that AI needs to run through is simply on a level that seems to be baked into life itself. To be able to create life, we need to first understand it. </p>
                    </div>
                </div>
                <div class="panel panel-default fadeInDown">
                    <div class="panel-body">
                        <div id="debunkingAI">
                            <button class="btn btn-primary" onclick=
                            "showDebunkingAI()">Show
                            Source</button>
                        </div>
                    </div>
                </div>
                <div class="panel panel-default fadeInDown">
                    <div class="panel-body">
                        <p>Known for being a technology journalist, Rupert Goodwins has written for multiple publications, such as: IT Week, PC Magazine(UK), The Daily Telegraph, and Nature. Goodwins is also known for writing Rupert's Diary starting in 1996, blogging before it became a thing.</p>
                    </div>
                </div>
                <div class="panel panel-default fadeInDown">
                    <div class="panel-body">
                        <p>Goodwins, Rupert. "Debunking the Biggest Myths about Artificial Intelligence." Ars Technica. Ars Technica and WIRED, 15 Dec. 2015. Web. 10 Apr. 2016.<p>
                    </div>
                </div>
            </div>
			
			
			<div class="panel-body" align="middle">
                <img src="comic3.jpg" align="middle"></img>
					<p>Adams, Scott. Dilbert. N.p., n.d. Web. 10 Apr. 2016. &lt;http://dilbert.com/strip/2015-11-30, http://dilbert.com/strip/2015-12-01, http://dilbert.com/strip/2015-12-02, http://dilbert.com/strip/2015-12-03, http://dilbert.com/strip/2015-12-04&gt;. </p>
            </div>
			
			
			<div class="col-lg-12 col-md-12 col-sm-12 col-xs-12" id="divSingularityBust">
                <div class="panel panel-default">
                    <div class="panel-heading" style="background: #000080">
                        <a href=
                        "https://www.youtube.com/watch?v=owppju3jwPE"
                        style="color: #FFFFFF">Singularity or Bust?</a><div style="color: #FFFFFF"> - Ben Goertzel</div>
                    </div>
                    <div class="panel-body">
                        <p>Being a staunch supporter of Vernor Vinge, Ben Goertzel takes us to China to show off what seems to be a singular robot. This robot, although primitive, seems to be able to interpret and synthesize responses. Goertzel expands upon this, heavily reinforcing that AI development is being driven by the entire human race. Coming out of history, it is only neccessary for the human world, and every individual, to feel a need to develop AI. The development of AI brings along not an ethical issue, but an evolutionist issue. Whether or not the expansion of human life into AI will eventually establish us as cows in a farm pasture, will be determined only by the development of such a higher being.<br><br>Goertzel then likens us to chimpanzees once AI is developed. What we manage to teach chimpanzees will eventually be what AI manages to teach us. The creation of a higher force is only changed by the human conditions that we specialize and compartamentalize away from AI. But the purposes of AI are not to revoke what makes us human, rather, it is to hopefully offer an extension of human life. But in a pessimistic sense, the development of AI may signify the development of the world into an era without humans, or an era with humans based as lower-beings.<br><br>Artificial intelligence will not be characterized by anything except by itself. The development of humans towards AI is simply following nature's trend (as evidence by the development of chimpanzees to humans). The inevitibility of this situation only goes to represent the inevitibility of humans to fully develop safeguards against a higher power rising from our products.</p>
                    </div>
                </div>
                <div class="panel panel-default fadeInDown">
                    <div class="panel-body">
                        <div id="singularityBust">
                            <button class="btn btn-primary" onclick=
                            "showSingularityBust()">Show
                            Source</button>
                        </div>
                    </div>
                </div>
                <div class="panel panel-default fadeInDown">
                    <div class="panel-body">
                        <p>Ben Goertzel is an individual heavily invested in artificial intelligence. Being the Chairman of Novamente LLC, he is also the Chairman of Artificial General Intelligence Society and the OpenCog Foundation. Goerzel is not only an advisor to Ray Kurzweil's Singularity University, but is also a Research Professor at Xiamen University, China.</p>
                    </div>
                </div>
                <div class="panel panel-default fadeInDown">
                    <div class="panel-body">
                        <p>Goertzel, Ben. "Singularity Or Bust." YouTube. YouTube, 03 Nov. 2013. Web. 11 Apr. 2016.</p>
                    </div>
                </div>
            </div>
			
			<div class="panel-body" align="middle">
                <img src="people.png" align="middle"></img>
				<p>Carl Sagan | Michio Kaku | Ray Kurzweil | Vernor Vinge | Arthur C. Clarke</p>
            </div>
			
			
			<div class="col-lg-12 col-md-12 col-sm-12 col-xs-12" id="divSingularityBust">
                <div class="panel panel-default">
                    <div class="panel-heading" style="background: #FFFFFF">
                        Bibliography
                    </div>
                    <div class="panel-body">
					<ul>
                        <li><p>Allen, Paul G. "The Singularity Isn't Near." MIT Technology Review. MIT Technology Review, 12 Oct. 2011. Web. 29 Mar. 2016.</p></li>
						<li><p>Kurzweil, Ray. "Don't Underestimate the Singularity." MIT Technology Review. MIT Technology Review, 20 Oct. 2011. Web. 29 Mar. 2016.</p></li>
						<li><p>The Nobel Prize. "Should We Fear or Welcome the Singularity?" YouTube. YouTube, 20 Jan. 2016. Web. 30 Mar. 2016.</p></li>
						<li><p>Vinge, Vernor. "The Coming Technological Singularity: How to Survive in the Post-human Era." Diss. San Diego State U, 1993. Abstract. In NASA. Lewis Research Center, Vision 21: Interdisciplinary Science and Engineering in the Era of Cyberspace P 11-22 (SEE N94-27358 07-12) (n.d.): 11-22. Print.</p></li>
						<li><p>Walsh, Toby. "The Singularity May Never Be Near." The Singularity May Never Be Near (2016): n. pag. Cornell University Library, 2016. Web. 10 Apr. 2016. &lt;http://arxiv.org/pdf/1602.06462v1.pdf>.</p></li>
						<li><p>Grossman, Lev. "2045: The Year Man Becomes Immortal." Time. Time Inc., 10 Feb. 2011. Web. 10 Apr. 2016.</p></li>
						<li><p>Goodwins, Rupert. "Debunking the Biggest Myths about Artificial Intelligence." Ars Technica. Ars Technica and WIRED, 15 Dec. 2015. Web. 10 Apr. 2016.</p></li>
						<li><p>Goertzel, Ben. "Singularity Or Bust." YouTube. YouTube, 03 Nov. 2013. Web. 11 Apr. 2016.</p></li>
					</ul>
					</div>
                </div>
            </div>
			
			
		
        </div>
    </div>
    <script src='http://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js'></script> 
    <script src="script.js"></script>
	<script src="sources.js"></script>
</body>
</html>